\begin{table}
\caption{Performance of tuned classifiers on the held-out test set.}
\label{tab:tuned_models_noq}
\begin{tabular}{lrrrrr}
\toprule
model & test_accuracy & test_precision & test_recall & test_f1 & test_roc_auc \\
\midrule
logreg_l2_tuned & 0.788000 & 0.946000 & 0.612000 & 0.743000 & 0.818000 \\
linear_svm_calibrated_tuned & 0.788000 & 0.944000 & 0.612000 & 0.743000 & 0.818000 \\
random_forest_tuned & 0.797000 & 0.915000 & 0.655000 & 0.763000 & 0.842000 \\
extra_trees_tuned & 0.794000 & 0.910000 & 0.652000 & 0.760000 & 0.837000 \\
gradient_boosting_tuned & 0.802000 & 0.928000 & 0.654000 & 0.767000 & 0.843000 \\
xgboost_tuned & 0.799000 & 0.922000 & 0.653000 & 0.765000 & 0.839000 \\
lightgbm_tuned & 0.801000 & 0.930000 & 0.651000 & 0.766000 & 0.842000 \\
catboost_tuned & 0.802000 & 0.924000 & 0.658000 & 0.769000 & 0.844000 \\
bagging_trees_tuned & 0.798000 & 0.922000 & 0.650000 & 0.763000 & 0.842000 \\
mlp_tuned & 0.790000 & 0.934000 & 0.625000 & 0.749000 & 0.821000 \\
\bottomrule
\end{tabular}
\end{table}
