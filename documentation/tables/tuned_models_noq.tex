\begin{table}[htbp]
  \centering
  \small
  \caption{Performance of tuned classifiers on the held-out test set.}
  \label{tab:tuned_models_noq}
  \begin{tabular}{lrrrrr}
    \toprule
    model & test\_accuracy & test\_precision & test\_recall & test\_f1 & test\_roc\_auc \\
    \midrule
    logreg\_l2\_tuned              & 0.788000 & 0.946000 & 0.612000 & 0.743000 & 0.818000 \\
    linear\_svm\_calibrated\_tuned & 0.788000 & 0.944000 & 0.612000 & 0.743000 & 0.818000 \\
    random\_forest\_tuned          & 0.797000 & 0.915000 & 0.655000 & 0.763000 & 0.842000 \\
    extra\_trees\_tuned            & 0.794000 & 0.910000 & 0.652000 & 0.760000 & 0.837000 \\
    gradient\_boosting\_tuned      & 0.802000 & 0.928000 & 0.654000 & 0.767000 & 0.843000 \\
    xgboost\_tuned                 & 0.799000 & 0.922000 & 0.653000 & 0.765000 & 0.839000 \\
    lightgbm\_tuned                & 0.801000 & 0.930000 & 0.651000 & 0.766000 & 0.842000 \\
    catboost\_tuned                & 0.802000 & 0.924000 & 0.658000 & 0.769000 & 0.844000 \\
    bagging\_trees\_tuned          & 0.798000 & 0.922000 & 0.650000 & 0.763000 & 0.842000 \\
    mlp\_tuned                     & 0.790000 & 0.934000 & 0.625000 & 0.749000 & 0.821000 \\
    \bottomrule
  \end{tabular}
\end{table}