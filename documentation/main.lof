\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Process Diagram of Special Project}}{22}{figure.caption.5}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Kernel density plots of six key features comparing clean and chimeric reads.}}{37}{figure.caption.11}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Test F1 of all baseline classifiers, showing that no single model clearly dominates and several achieve comparable performance.}}{39}{figure.caption.13}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces Comparison of test F1 (left) and ROC--AUC (right) for baseline and tuned models. Hyperparameter tuning yields small but consistent gains, particularly for tree-based ensembles.}}{41}{figure.caption.15}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces Confusion matrices for the four representative models on the held-out test set. All models show more false negatives (chimeric reads called clean) than false positives.}}{43}{figure.caption.16}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces ROC (left) and precision--recall (right) curves for the four representative models on the held-out test set. Tree-based ensembles cluster closely, with logistic regression performing slightly but consistently worse.}}{44}{figure.caption.17}%
