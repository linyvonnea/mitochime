\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Process Diagram of Special Project}}{22}{figure.3.1}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Test F1 of all baseline classifiers, showing that no single model clearly dominates and several achieve comparable performance.}}{36}{figure.4.1}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Comparison of test F1 (left) and ROC--AUC (right) for baseline and tuned models. Hyperparameter tuning yields small but consistent gains, particularly for tree-based ensembles.}}{38}{figure.4.2}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces Confusion matrices for the four representative models on the held-out test set. All models show more false negatives (chimeric reads called clean) than false positives.}}{40}{figure.4.3}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces ROC (left) and precision--recall (right) curves for the four representative models on the held-out test set. Tree-based ensembles cluster closely, with logistic regression performing slightly but consistently worse.}}{41}{figure.4.4}%
