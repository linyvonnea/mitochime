% \section*{Chapter 4}\label{sec:results}
\chapter{Results and Discussion}

This chapter presents the performance of the proposed feature set and machine learning models for detecting PCR-induced chimeric reads in simulated mitochondrial Illumina data. The behaviour of the extracted features is first examined through descriptive and correlation analyses, followed by a comparison of baseline and tuned classifiers. The chapter then examines model performance in detail and investigates the contribution of individual features and feature families, including the impact of feature selection on classification performance.

The final dataset contained 31{,}986 reads for training and 7{,}997 reads for testing, with classes balanced (approximately 4{,}000 clean and 4{,}000 chimeric reads in the test split).

\section{Descriptive Analysis of Features}
\subsection{Summary Statistics Per Class}

Summary statistics were computed separately for clean reads (class~0) and chimeric reads (class~1) to characterize the distributional behavior of the features. For each feature, the mean, standard deviation, median, first and third quartiles (Q1, Q3), interquartile range (IQR), minimum, maximum, and sample size ($n$) were calculated.

Only a subset of the features is summarized in the main text to highlight key trends, and not all summary statistics columns are shown for brevity. The complete set of per-class summary statistics for all features is provided in Appendix~\ref{app:summary_stats} (Table~\ref{tab:feature_summary_full}).

\subsubsection{Alignment and Supplementary Alignment Features}

Features related to supplementary alignments show strong separation between classes. Chimeric reads frequently exhibit supplementary alignments, reflected by higher values of \texttt{has\_sa}, \texttt{sa\_count}, and \texttt{num\_segments}, whereas clean reads consistently show a single alignment segment with no supplementary mappings. Table~\ref{tab:key_feature_summary} shows that \texttt{has\_sa} is present in chimeric reads (mean = 0.406) but absent in clean reads (mean = 0.000), while \texttt{num\_segments} increases from a constant value of 1.000 in clean reads to a mean of 1.406 in chimeric reads. These patterns align with the expected structure of chimeric reads and indicate that alignment-based features are highly informative.

\subsubsection{Clipping-Based Features}

Clipping-related features, including \texttt{softclip\_left}, \texttt{softclip\_right}, and \texttt{total\_clipped\_bases}, display higher values and broader distributions in chimeric reads. In chimeric reads, \texttt{total\_clipped\_bases} reaches 25.44 on average, with a median of 19.0 and an IQR of 48.0, while \texttt{softclip\_left} and \texttt{softclip\_right} have averages of 12.55 and 12.90, medians of 0.0, and IQRs of 19.0. Clean reads maintain values near zero across all these metrics. These patterns indicate substantial clipping and increased variability in chimeric reads, reflecting junction-like alignment fragmentation, whereas clean reads remain unaltered.
\subsubsection{K-mer Distribution Features}

K-merâ€“based features, including \texttt{kmer\_js\_divergence} and \texttt{kmer\_cosine\_diff}, show only minor differences between clean and chimeric reads. In chimeric reads, \texttt{kmer\_js\_divergence} has a mean of 0.974 with a median of 0.986, and \texttt{kmer\_cosine\_diff} has a mean of 0.974 with a median of 0.986. Clean reads show similar values, with \texttt{kmer\_js\_divergence} at 0.976 with a median of 0.986, and \texttt{kmer\_cosine\_diff} at 0.976 with a median of 0.986. The close similarity of the means, medians, and overall ranges of values indicates that these features alone provide limited ability to distinguish clean from chimeric reads.

\subsubsection{Microhomology Features}

Microhomology-related features, including \texttt{microhomology\_length} and \linebreak \texttt{microhomology\_gc}, exhibit nearly identical summary statistics between clean and chimeric reads. Most reads in both classes have short or zero-length microhomologies. Table~\ref{tab:key_feature_summary} shows that \texttt{microhomology\_gc} has a mean of 0.172 and a median of 0.0 in both clean and chimeric reads, while \texttt{microhomology\_length} averages 0.458 with a median of 0.0 in chimeric reads and 0.462 with a median of 0.0 in clean reads. These values indicate that microhomology features alone provide limited discriminatory power and are more appropriately considered as supporting evidence.

Overall, the summary statistics indicate that alignment-based and clipping-based features provide the strongest class separation, k-mer features contribute limited but complementary signal, and microhomology features exhibit minimal discriminative power on their own. These observations motivate the combined multi-feature approach used in subsequent modeling and evaluation.

\begin{table}[H]
\centering
\caption{Summary statistics of selected key features by class.}
\label{tab:key_feature_summary}
\begin{tabular}{llrrrr}
\toprule
Feature & Class & Mean & Std & Median & IQR \\
\midrule
has\_sa & chimeric & 0.406 & 0.491 & 0.0 & 1.0 \\
has\_sa & clean    & 0.000 & 0.000 & 0.0 & 0.0 \\

num\_segments & chimeric & 1.406 & 0.491 & 1.0 & 1.0 \\
num\_segments & clean    & 1.000 & 0.000 & 1.0 & 0.0 \\

softclip\_left & chimeric & 12.55 & 21.90 & 0.0 & 19.0 \\
softclip\_left & clean    & 0.23  & 1.54  & 0.0 & 0.0  \\

softclip\_right & chimeric & 12.90 & 22.12 & 0.0 & 19.0 \\
softclip\_right & clean    & 0.21  & 1.51  & 0.0 & 0.0  \\

total\_clipped\_bases & chimeric & 25.44 & 25.48 & 19.0 & 48.0 \\
total\_clipped\_bases & clean    & 0.44  & 2.16  & 0.0  & 0.0  \\

kmer\_js\_divergence & chimeric & 0.974 & 0.025 & 0.986 & 0.043 \\
kmer\_js\_divergence & clean    & 0.976 & 0.025 & 0.986 & 0.040 \\

kmer\_cosine\_diff & chimeric & 0.974 & 0.026 & 0.986 & 0.042 \\
kmer\_cosine\_diff & clean    & 0.976 & 0.025 & 0.986 & 0.041 \\

microhomology\_length & chimeric & 0.458 & 0.755 & 0.0 & 1.0 \\
microhomology\_length & clean    & 0.462 & 0.758 & 0.0 & 1.0 \\

microhomology\_gc  & chimeric & 0.172 & 0.361 & 0.0    & 0.0    \\
microhomology\_gc  & clean    & 0.172 & 0.361 & 0.0    & 0.0    \\
\bottomrule
\end{tabular}
\end{table}

Boxplots were generated for each feature, with the x-axis representing the class (clean reads and chimeric reads) and the y-axis representing the feature value. Figure~\ref{fig:boxplots_all_features} presents a panel of selected key features, while boxplots for all numeric features are provided in Appendix~\ref{app:boxplots_by_family}.

For clipping-related features (\texttt{softclip\_left}, \texttt{softclip\_right},\linebreak and \texttt{total\_clipped\_bases}), chimeric reads exhibit higher medians and longer upper whiskers than clean reads, indicating increased variability and the presence of split alignments.

Supplementary alignment features (\texttt{has\_sa} and \texttt{sa\_count}), show that clean reads are largely zero, whereas chimeric reads display a wider distribution, reflecting frequent supplementary alignments.

K-mer metrics (\texttt{kmer\_js\_divergence} and \texttt{kmer\_cosine\_diff}) show a slight upward shift for chimeric reads, but substantial overlap with clean reads indicates low discriminative power.

Microhomology features (\texttt{microhomology\_length} and \texttt{microhomology\_gc}) have nearly overlapping distributions for both classes, consistent with their low standalone predictive importance.

\begin{figure}[H]
\centering

\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{../notebooks/figures/boxplots/box_softclip_left.png}
    \caption{Softclip left}
    \label{fig:box_softclip_left}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{../notebooks/figures/boxplots/box_softclip_right.png}
    \caption{Softclip right}
    \label{fig:box_softclip_right}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{../notebooks/figures/boxplots/box_has_sa.png}
    \caption{Has SA}
    \label{fig:box_has_sa}
\end{subfigure}

\vspace{0.5em}

\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{../notebooks/figures/boxplots/box_sa_count.png}
    \caption{SA count}
    \label{fig:box_sa_count}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{../notebooks/figures/boxplots/box_total_clipped_bases.png}
    \caption{Total clipped bases}
    \label{fig:box_total_clipped_bases}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{../notebooks/figures/boxplots/box_kmer_js_divergence.png}
    \caption{K-mer JS divergence}
    \label{fig:box_kmer_js_divergence}
\end{subfigure}

\vspace{0.5em}

\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{../notebooks/figures/boxplots/box_kmer_cosine_diff.png}
    \caption{K-mer cosine difference}
    \label{fig:box_kmer_cosine_diff}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{../notebooks/figures/boxplots/box_microhomology_length.png}
    \caption{Microhomology length}
    \label{fig:box_microhomology_length}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{../notebooks/figures/boxplots/box_microhomology_gc.png}
    \caption{Microhomology GC}
    \label{fig:box_microhomology_gc}
\end{subfigure}

\caption{Boxplots of selected features for clean and chimeric reads.}
\label{fig:boxplots_all_features}
\end{figure}


\subsection{Correlation Analysis of Extracted Features}

A feature correlation heatmap (Figure~\ref{fig:correlation_heatmap}) was generated to examine relationships among the extracted variables and to identify patterns of redundancy and independence within the feature set. The analysis shows that alignment-related and clipping-related features form a strongly correlated cluster, including indicators of supplementary alignments, alignment segment counts, positional differences, and soft-clipping measures. These features capture related aspects of alignment fragmentation, which is a known characteristic of chimeric reads, and several show moderate correlations with the class label, supporting their relevance for distinguishing chimeric from clean reads. In contrast, general read-quality and alignment-quality metrics, such as read length, base quality, and mapping quality, exhibit weak correlations with most split-alignment features, indicating that they provide distinct information rather than overlapping with alignment-derived signals. Sequence-based features display a similar pattern of independence, as k-mer divergence metrics show weak correlations with other feature groups, while microhomology features exhibit generally low correlations with both alignment-based and k-mer-based features. Overall, the correlation structure highlights intentional redundancy within alignment-derived features and clear separation between feature families, supporting the use of features that capture different aspects of chimeric read characteristics to improve chimera classification.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{../notebooks/figures/correlation.png}
    \caption{Feature correlation heatmap showing relationships among alignment-derived and sequence-derived features.}
    \label{fig:correlation_heatmap}
\end{figure}


\section{Baseline Classification Performance}

Table~\ref{tab:baseline_models_noq} summarises the performance of eleven classifiers trained on the engineered feature set using five-fold cross-validation and evaluated on the held-out test set. All models were optimised using default hyperparameters, without dedicated tuning.

The dummy baseline, which always predicts the same class regardless of the input features, achieved an accuracy of 0.50 and test F1-score of 0.67. This reflects the balanced class distribution and provides a lower bound for meaningful performance.

Across other models, test F1-scores clustered in a narrow band between approximately 0.74 and 0.77 and ROC--AUC values between 0.82 and 0.84. Gradient boosting, CatBoost, LightGBM, XGBoost, bagging trees, random forest, and multilayer perceptron (MLP) all produced very similar scores, with CatBoost and gradient boosting slightly ahead (test F1 $\approx 0.77$, ROC--AUC $\approx 0.84$). Linear models (logistic regression and calibrated linear SVM) performed only marginally worse (test F1 $\approx 0.74$), while Gaussian Naive Bayes lagged behind with substantially lower F1 ($\approx 0.65$) despite very high precision for the chimeric class.

\input{tables/baseline_models_noq}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.6\linewidth]{figures/baseline_f1.png}
  \caption{Test F1 of all baseline classifiers, showing that no single model clearly dominates and several achieve comparable performance.}
  \label{fig:baseline_f1}
\end{figure}

\section{Effect of Hyperparameter Tuning}

To assess whether performance could be improved further, ten model families underwent randomised hyperparameter search. The tuned metrics are summarised in Table~\ref{tab:tuned_models_noq}. Overall, tuning yielded modest but consistent gains for tree-based ensembles and boosting methods, while leaving linear models essentially unchanged or slightly worse.

CatBoost, gradient boosting, LightGBM, XGBoost, random forest, bagging trees, and MLP all experienced small increases in test F1 (typically $\Delta \mathrm{F1} \approx 0.002$--0.009) and ROC--AUC (up to $\Delta \mathrm{AUC} \approx 0.008$). After tuning, CatBoost remained the best performer with test accuracy 0.80, precision 0.92, recall 0.66, F1-score 0.77, and ROC--AUC 0.84. Gradient boosting achieved almost identical performance (F1 0.77, AUC 0.84). Random forest and bagging trees also improved to F1 scores around 0.76 with AUC $\approx 0.84$.

\input{tables/tuned_models_noq}

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figures/f1_auc_tuning.png}
  \caption{Comparison of test F1 (left) and ROC--AUC (right) for baseline and tuned models.}
  \label{fig:f1_auc_tuning}
\end{figure}

Because improvements are small and within cross-validation variability, tuning was interpreted as stabilising and slightly refining the models rather than completely altering their behaviour or their relative ranking.

\section{Detailed Evaluation of Representative Models}

For interpretability and diversity, four tuned models were selected for deeper analysis: CatBoost (best-performing boosted tree), scikit-learn gradient boosting (canonical gradient-boosting implementation), random forest (non-boosted ensemble baseline), and $L_2$-regularised logistic regression (linear baseline). All models were trained on the engineered feature set and evaluated on the same held-out test data.

\subsection{Confusion Matrices and Error Patterns}

Classification reports and confusion matrices for the four models reveal consistent patterns. CatBoost and gradient boosting both reached overall accuracy of approximately 0.80 with similar macro-averaged F1 scores ($\sim 0.80$). For CatBoost, precision and recall for clean reads were 0.73 and 0.95, respectively, while for chimeric reads they were 0.92 and 0.66 (F1 = 0.77). Gradient boosting showed nearly identical trade-offs.

Random forest attained slightly lower accuracy (0.80) and chimeric F1 (0.76), whereas logistic regression achieved the lowest accuracy among the four (0.79) and chimeric F1 (0.74), although it provided the highest chimeric precision (0.95) at the cost of lower recall (0.61).

Across all models, errors were asymmetric. False negatives (chimeric reads predicted as clean) were more frequent than false positives. For example, CatBoost misclassified 1{,}369 chimeric reads as clean but only 215 clean reads as chimeric. This pattern indicates that the models are conservative and prioritise avoiding false chimera calls at the expense of missing some true chimeras. Consultation with PGC Visayas indicated that this conservative behavior is generally acceptable, though further evaluation and testing will be required to assess its impact on downstream analyses.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.45\linewidth]{figures/cm_catboost.png}
  \includegraphics[width=0.45\linewidth]{figures/cm_gradient_boosting.png}\\[4pt]
  \includegraphics[width=0.45\linewidth]{figures/cm_random_forest.png}
  \includegraphics[width=0.45\linewidth]{figures/cm_logreg_l2.png}
  \caption{Confusion matrices for the four representative models on the held-out test set.}
  \label{fig:confusion_matrices}
\end{figure}

\subsection{ROC and Precision--Recall Curves}

Receiver operating characteristic (ROC) and precision--recall (PR) curves as shown in Figure~\ref{fig:roc_pr_curves} further support the similarity among the top models. The three tree-based ensembles (CatBoost, gradient boosting, random forest) achieved ROC--AUC values of approximately 0.84 and average precision (AP) around 0.88. Logistic regression performed slightly worse (AUC $\approx 0.82$, AP $\approx 0.87$) but still substantially better than the dummy baseline.

The PR curves show that precision remains above 0.9 across a broad range of recall values (up to roughly 0.5--0.6), after which precision gradually declines. This behaviour indicates that the models can assign very high confidence to a subset of chimeric reads, while more ambiguous reads can only be recovered by accepting lower precision.

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figures/roc_pr_curves.png}
  \caption{ROC (left) and precision--recall (right) curves for the four representative models on the held-out test set.}
  \label{fig:roc_pr_curves}
\end{figure}

\section{Feature Importance}

\subsection{Permutation Importance of Individual Features}

To understand how each classifier made predictions, feature importance was quantified using permutation importance. This analysis was applied to four representative models: CatBoost, Gradient Boosting, Random Forest, and L$_2$-regularized Logistic Regression.

As shown in Figure~\ref{fig:all_models_imp}, the total number of clipped bases consistently provides a strong predictive signal, particularly in Random Forest, Gradient Boosting, and L$_2$-regularized Logistic Regression. CatBoost differs by assigning the highest importance to k-mer divergence metrics such as \texttt{kmer\_js\_divergence}, which capture subtle sequence changes resulting from structural variants or PCR-induced chimeras. Soft-clipping features (\texttt{softclip\_left} and \texttt{softclip\_right}) provide more information around breakpoints, complementing these primary signals in all models except Gradient Boosting. L$_2$-regularized Logistic Regression relies more on alignment-based split-read metrics.

Overall, these results indicate that accurate detection of chimeric reads relies on both alignment-based signals and k-mer compositional information. Explicit microhomology features contribute minimally in this analysis, and combining both alignment-based and sequence-level features enhances model sensitivity and specificity.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/catboost_imp.png}
        \caption{CatBoost}
        \label{fig:catboost_imp}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/gradient_imp.png}
        \caption{Gradient Boosting}
        \label{fig:gradient_imp}
    \end{subfigure}

    \vspace{0.5em}

    \begin{subfigure}[b]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/randomforest_imp.png}
        \caption{Random Forest}
        \label{fig:randomforest_imp}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/logreg_imp.png}
        \caption{L$_2$-regularized Logistic Regression}
        \label{fig:logreg_imp}
    \end{subfigure}

    \caption{Permutation-based feature importance for four representative classifiers.}
    \label{fig:all_models_imp}
\end{figure}

\subsection{Feature Family Importance}

To evaluate the contribution of broader signals, features were grouped into five families: 
SA\_structure (supplementary alignment and segment metrics, e.g., 
\texttt{has\_sa}, \texttt{sa\_count}, \texttt{sa\_min\_delta\_pos}, \texttt{sa\_mean\_nm}, etc.), 
Clipping (\texttt{softclip\_left}, \texttt{softclip\_right}, \texttt{total\_clipped\_bases}, 
\texttt{breakpoint\_read\_pos}), 
Kmer\_jump (\texttt{kmer\_cosine\_diff}, \texttt{kmer\_js\_divergence}), 
Micro\_homology (
\texttt{microhomology\_length}, \texttt{microhomology\_gc}), 
and Other (e.g., \texttt{mapq}).

Aggregated analyses reveal consistent patterns across models. In CatBoost, the Clipping family has the largest cumulative contribution (0.14), followed by Kmer\_jump (0.12), with Other features contributing minimally (0.005) and SA\_structure (0.003) and Micro\_homology (0.003) providing minimal predictive power. Gradient Boosting shows a similar trend, with Clipping (0.13) dominating, Kmer\_jump (0.11) secondary, and the remaining families contributing negligibly. Random Forest integrates both Clipping (0.088) and Kmer\_jump (0.08) effectively, while SA\_structure, Micro\_homology, and Other remain minor contributors. L$_2$-regularized Logistic Regression emphasizes Clipping (0.09) and SA\_structure (0.07), with Kmer\_jump and Micro\_homology having minimal impact.

Both feature-level and aggregated analyses indicate that detection of chimeric reads in this dataset relies primarily on alignment irregularities (Clipping) and k-mer compositional shifts (Kmer\_jump), which often arise from PCR-induced template switching events, while explicit microhomology features contribute minimally.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{catboost_family.png}
        \caption{CatBoost}
        \label{fig:catboost_family}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{gradient_family.png}
        \caption{Gradient Boosting}
        \label{fig:gb_family}
    \end{subfigure}
    
    \vspace{0.5em}
    
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{randomforest_family.png}
        \caption{Random Forest}
        \label{fig:rf_family}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{logreg_family.png}
        \caption{L$_2$-regularized Logistic Regression}
        \label{fig:logreg_family}
    \end{subfigure}

    \caption{Aggregated feature family importance across four models.}
    \label{fig:feature_family_all}
\end{figure}

\section{Feature Selection}

Feature selection was performed to identify the smallest subset reaching 95\% cumulative importance. Three models were evaluated as references: the full model with all 23 features, a reduced model with the top-\(k\) features, and an ablation model excluding microhomology features, using a tuned CatBoost classifier to assess feature contributions and overall classification performance.

\subsection{Cumulative Importance Curve}

The cumulative importance curve was computed using the tuned CatBoost classifier. Figure~\ref{fig:cumulative_importance} illustrates the contribution of features sorted by importance. The curve rises steeply for the first few features and then gradually plateaus, indicating that a small number of features capture most of the model's predictive power. A cumulative importance of 95\% is reached at \(k = 4\) features, which are \texttt{total\_clipped\_bases}, \texttt{kmer\_js\_divergence}, \texttt{kmer\_cosine\_diff}, and \texttt{softclip\_left}. 

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{../notebooks/figures/catboost_cumulative_importance.png}
\caption{Cumulative importance curve of features sorted by importance.}
\label{fig:cumulative_importance}
\end{figure}

\subsection{Performance Comparison Across Feature Sets}

Classification performance was compared across three feature sets using a tuned CatBoost classifier. The full model, incorporating all 23 engineered features, achieved an F1 score of 0.769 and a ROC--AUC of 0.844. A reduced model using only the top four features (\texttt{total\_clipped\_bases}, \texttt{kmer\_js\_divergence}, \texttt{kmer\_cosine\_diff}, and \texttt{softclip\_left}) achieved nearly equivalent performance with an F1 of 0.767 and a ROC--AUC of 0.835. An ablation model excluding microhomology features (\texttt{microhomology\_length} and \texttt{microhomology\_gc}) also performed comparably, with an F1 of 0.768 and ROC--AUC of 0.845. These results indicate that clipping and k-mer features capture almost all predictive signal, while microhomology features are largely redundant in this dataset.

\begin{table}[H]
\centering
\caption{Test set performance of three feature set variants using tuned CatBoost.}
\label{tab:catboost_feature_sets}
\begin{tabular}{lrrr}
\toprule
Variant & No. of Features & Test F1 & ROC--AUC \\
\midrule
Full CatBoost & 23 & 0.769 & 0.844 \\
Selected (top-4) & 4 & 0.767 & 0.835 \\
No microhomology & 21 & 0.768 & 0.845 \\
\bottomrule
\end{tabular}
\end{table}

Figure~\ref{fig:catboost_three_sets} presents a bar chart comparing F1 and ROC--AUC across the three variants, with the x-axis showing the model variants and two bars per group representing the F1 and ROC--AUC values.

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{../notebooks/figures/catboost_three_sets.png}
\caption{Comparison of F1 and ROC--AUC for the full, top-4 selected, and no-microhomology feature set variants.}
\label{fig:catboost_three_sets}
\end{figure}

\subsection{Interpretation and Final Feature Set Choice}

The full 23-feature model is retained as the primary configuration for the remainder of the study, while the four-feature subset serves as a lightweight alternative. Clipping features reflect alignment junctions and mapping disruptions typical of chimeric reads, and k-mer divergence captures changes in sequence composition across breakpoints. Microhomology features appear largely redundant, as their signal is either indirectly represented by clipping and k-mer features or not strongly expressed in the simulation dataset.


\section{Summary of Findings}

All evaluated machine learning models substantially outperformed the dummy baseline, demonstrating that the engineered feature set contains meaningful signals for detecting PCR-induced chimeric reads. Across classifiers, the best-performing models achieved test F1-scores of approximately 0.77 and ROC--AUC values around 0.84 on held-out simulated mitochondrial reads, indicating reliable discrimination between clean and chimeric sequences. Among the tested approaches, tree-based ensemble and boosting methods consistently showed the strongest and most stable performance. In particular, CatBoost and Gradient Boosting ranked among the top models across multiple evaluation metrics, both before and after hyperparameter tuning. These results suggest that non-linear ensemble methods are well suited to capturing the interaction between alignment-derived and sequence-derived features in this setting.

Analysis of feature behaviour revealed clear differences in how effectively feature groups distinguished clean and chimeric reads. Alignment- and clipping-based features, such as soft-clipping measures and total clipped bases, showed strong separation between clean and chimeric reads and emerged as the most informative signals. K-mer divergence features provided additional but weaker separation, contributing complementary information beyond alignment irregularities. In contrast, microhomology features and several supplementary alignment (SA) structure metrics exhibited minimal class separation and contributed little to overall predictive performance.

Feature selection results further supported these observations. A reduced subset of four features, dominated by clipping-based and k-mer divergence metrics, achieved nearly identical performance to the full 23-feature model. Moreover, removing explicit microhomology features did not degrade performance and in some cases resulted in slightly improved metrics, suggesting that these features are largely redundant under the simulated conditions tested.

Overall, these findings suggest that alignment-based and k-mer--based features provide sufficient signal to detect PCR-induced chimeric reads in simulated mitochondrial data, supporting the use of a compact and interpretable machine learning approach as a pre-assembly chimera detection step.
