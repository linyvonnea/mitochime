% \section*{Chapter 4}\label{sec:results}
\chapter{Results and Discussion}

This chapter presents the performance of the proposed feature set and machine learning models for detecting PCR-induced chimeric reads in simulated mitochondrial Illumina data. The behaviour of the extracted features is first examined through descriptive and correlation analyses, followed by a comparison of baseline and tuned classifiers. The chapter then examines model performance in detail and investigates the contribution of individual features and feature families, including the impact of feature selection on classification performance.

The final dataset contained 31{,}986 reads for training and 7{,}997 reads for testing, with classes balanced (approximately 4{,}000 clean and 4{,}000 chimeric reads in the test split).

\section{Descriptive Analysis of Features}
\subsection{Summary Statistics Per Class}

Summary statistics were computed separately for clean reads (class~0) and chimeric reads (class~1) to characterize the distributional behavior of the features. For each feature, the mean, standard deviation, median, first and third quartiles (Q1, Q3), interquartile range (IQR), minimum, maximum, and sample size ($n$) were calculated.

Only a subset of the features is summarized in the main text to highlight key trends, and not all summary statistics columns are shown for brevity. The complete set of per-class summary statistics for all features is provided in Appendix~\ref{app:summary_stats} (Table~\ref{tab:feature_summary_full}).

\subsubsection{Alignment and Supplementary Alignment Features}

Features related to supplementary alignments show strong separation between classes. Chimeric reads frequently exhibit supplementary alignments, reflected by higher values of \texttt{has\_sa}, \texttt{sa\_count}, and \texttt{num\_segments}, whereas clean reads consistently show a single alignment segment with no supplementary mappings. Table~\ref{tab:key_feature_summary} shows that \texttt{has\_sa} is present in chimeric reads (mean = 0.406) but absent in clean reads (mean = 0.000), while \texttt{num\_segments} increases from a constant value of 1.000 in clean reads to a mean of 1.406 in chimeric reads. These patterns align with the expected structure of chimeric reads and indicate that alignment-based features are highly informative.

\subsubsection{Clipping-Based Features}

Clipping-related features, including \texttt{softclip\_left}, \texttt{softclip\_right}, and \texttt{total\_clipped\_bases}, display higher values and broader distributions in chimeric reads. In chimeric reads, \texttt{total\_clipped\_bases} reaches 25.44 on average, with a median of 19.0 and an IQR of 48.0, while \texttt{softclip\_left} and \texttt{softclip\_right} have averages of 12.55 and 12.90, medians of 0.0, and IQRs of 19.0. Clean reads maintain values near zero across all these metrics. These patterns indicate substantial clipping and increased variability in chimeric reads, reflecting junction-like alignment fragmentation, whereas clean reads remain unaltered.
\subsubsection{K-mer Distribution Features}

K-merâ€“based features, including \texttt{kmer\_js\_divergence} and \texttt{kmer\_cosine\_diff}, show only minor differences between clean and chimeric reads. In chimeric reads, \texttt{kmer\_js\_divergence} has a mean of 0.974 with a median of 0.986, and \texttt{kmer\_cosine\_diff} has a mean of 0.974 with a median of 0.986. Clean reads show similar values, with \texttt{kmer\_js\_divergence} at 0.976 with a median of 0.986, and \texttt{kmer\_cosine\_diff} at 0.976 with a median of 0.986. The close similarity of the means, medians, and overall ranges of values indicates that these features alone provide limited ability to distinguish clean from chimeric reads.

\subsubsection{Microhomology Features}

Microhomology-related features, including \texttt{microhomology\_length} and \linebreak \texttt{microhomology\_gc}, exhibit nearly identical summary statistics between clean and chimeric reads. Most reads in both classes have short or zero-length microhomologies. Table~\ref{tab:key_feature_summary} shows that \texttt{microhomology\_gc} has a mean of 0.172 and a median of 0.0 in both clean and chimeric reads, while \texttt{microhomology\_length} averages 0.458 with a median of 0.0 in chimeric reads and 0.462 with a median of 0.0 in clean reads. These values indicate that microhomology features alone provide limited discriminatory power and are more appropriately considered as supporting evidence.

Overall, the summary statistics indicate that alignment-based and clipping-based features provide the strongest class separation, k-mer features contribute limited but complementary signal, and microhomology features exhibit minimal discriminative power on their own. These observations motivate the combined multi-feature approach used in subsequent modeling and evaluation.

\begin{table}[H]
\centering
\caption{Summary statistics of selected key features by class.}
\label{tab:key_feature_summary}
\begin{tabular}{llrrrr}
\toprule
Feature & Class & Mean & Std & Median & IQR \\
\midrule
has\_sa & chimeric & 0.406 & 0.491 & 0.0 & 1.0 \\
has\_sa & clean    & 0.000 & 0.000 & 0.0 & 0.0 \\

num\_segments & chimeric & 1.406 & 0.491 & 1.0 & 1.0 \\
num\_segments & clean    & 1.000 & 0.000 & 1.0 & 0.0 \\

softclip\_left & chimeric & 12.55 & 21.90 & 0.0 & 19.0 \\
softclip\_left & clean    & 0.23  & 1.54  & 0.0 & 0.0  \\

softclip\_right & chimeric & 12.90 & 22.12 & 0.0 & 19.0 \\
softclip\_right & clean    & 0.21  & 1.51  & 0.0 & 0.0  \\

total\_clipped\_bases & chimeric & 25.44 & 25.48 & 19.0 & 48.0 \\
total\_clipped\_bases & clean    & 0.44  & 2.16  & 0.0  & 0.0  \\

kmer\_js\_divergence & chimeric & 0.974 & 0.025 & 0.986 & 0.043 \\
kmer\_js\_divergence & clean    & 0.976 & 0.025 & 0.986 & 0.040 \\

kmer\_cosine\_diff & chimeric & 0.974 & 0.026 & 0.986 & 0.042 \\
kmer\_cosine\_diff & clean    & 0.976 & 0.025 & 0.986 & 0.041 \\

microhomology\_length & chimeric & 0.458 & 0.755 & 0.0 & 1.0 \\
microhomology\_length & clean    & 0.462 & 0.758 & 0.0 & 1.0 \\

microhomology\_gc  & chimeric & 0.172 & 0.361 & 0.0    & 0.0    \\
microhomology\_gc  & clean    & 0.172 & 0.361 & 0.0    & 0.0    \\
\bottomrule
\end{tabular}
\end{table}

Boxplots were generated for each feature, with the x-axis representing the class (clean reads and chimeric reads) and the y-axis representing the feature value. Figure~\ref{fig:boxplots_all_features} presents a panel of selected key features, while boxplots for all numeric features are provided in Appendix~\ref{app:boxplots_by_family}.

For clipping-related features (\texttt{softclip\_left}, \texttt{softclip\_right},\linebreak and \texttt{total\_clipped\_bases}), chimeric reads exhibit higher medians and longer upper whiskers than clean reads, indicating increased variability and the presence of split alignments.

Supplementary alignment features (\texttt{has\_sa} and \texttt{sa\_count}), show that clean reads are largely zero, whereas chimeric reads display a wider distribution, reflecting frequent supplementary alignments.

K-mer metrics (\texttt{kmer\_js\_divergence} and \texttt{kmer\_cosine\_diff}) show a slight upward shift for chimeric reads, but substantial overlap with clean reads indicates low discriminative power.

Microhomology features (\texttt{microhomology\_length} and \texttt{microhomology\_gc}) have nearly overlapping distributions for both classes, consistent with their low standalone predictive importance.

\begin{figure}[H]
\centering

\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{../notebooks/figures/boxplots/box_softclip_left.png}
    \caption{Softclip left}
    \label{fig:box_softclip_left}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{../notebooks/figures/boxplots/box_softclip_right.png}
    \caption{Softclip right}
    \label{fig:box_softclip_right}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{../notebooks/figures/boxplots/box_has_sa.png}
    \caption{Has SA}
    \label{fig:box_has_sa}
\end{subfigure}

\vspace{0.5em}

\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{../notebooks/figures/boxplots/box_sa_count.png}
    \caption{SA count}
    \label{fig:box_sa_count}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{../notebooks/figures/boxplots/box_total_clipped_bases.png}
    \caption{Total clipped bases}
    \label{fig:box_total_clipped_bases}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{../notebooks/figures/boxplots/box_kmer_js_divergence.png}
    \caption{K-mer JS divergence}
    \label{fig:box_kmer_js_divergence}
\end{subfigure}

\vspace{0.5em}

\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{../notebooks/figures/boxplots/box_kmer_cosine_diff.png}
    \caption{K-mer cosine difference}
    \label{fig:box_kmer_cosine_diff}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{../notebooks/figures/boxplots/box_microhomology_length.png}
    \caption{Microhomology length}
    \label{fig:box_microhomology_length}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{../notebooks/figures/boxplots/box_microhomology_gc.png}
    \caption{Microhomology GC}
    \label{fig:box_microhomology_gc}
\end{subfigure}

\caption{Boxplots of selected features for clean and chimeric reads.}
\label{fig:boxplots_all_features}
\end{figure}


\subsection{Correlation Analysis of Extracted Features}

A feature correlation heatmap (Figure~\ref{fig:correlation_heatmap}) was generated to examine relationships among the extracted variables and to identify patterns of redundancy and independence within the feature set. The analysis shows that alignment-related and clipping-related features form a strongly correlated cluster, including indicators of supplementary alignments, alignment segment counts, positional differences, and soft-clipping measures. These features capture related aspects of alignment fragmentation, which is a known characteristic of chimeric reads, and several show moderate correlations with the class label, supporting their relevance for distinguishing chimeric from clean reads. In contrast, general read-quality and alignment-quality metrics, such as read length, base quality, and mapping quality, exhibit weak correlations with most split-alignment features, indicating that they provide distinct information rather than overlapping with alignment-derived signals. Sequence-based features display a similar pattern of independence, as k-mer divergence metrics show weak correlations with other feature groups, while microhomology features exhibit generally low correlations with both alignment-based and k-mer-based features. Overall, the correlation structure highlights intentional redundancy within alignment-derived features and clear separation between feature families, supporting the use of features that capture different aspects of chimeric read characteristics to improve chimera classification.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{../notebooks/figures/correlation.png}
    \caption{Feature correlation heatmap showing relationships among alignment-derived and sequence-derived features.}
    \label{fig:correlation_heatmap}
\end{figure}


\section{Baseline Classification Performance}

Table~\ref{tab:baseline_models_test_metrics} summarises the performance of thirteen baseline classifiers trained on the engineered feature set and evaluated on a held-out test set. All models were trained using default hyperparameters, without dedicated tuning.

The dummy baseline, which always predicts the same class regardless of the input features, achieved a test accuracy of approximately 0.50 and an F1-score of 0.67. This reflects the balanced class distribution and serves as a lower bound for meaningful model performance.

Across the remaining models, test F1-scores clustered within a narrow range, from approximately 0.75 to 0.78, with ROC--AUC values between about 0.82 and 0.85. Ensemble methods, including gradient boosting, CatBoost, LightGBM, XGBoost, bagging trees, and random forest, exhibited very similar performance. Among these, CatBoost and gradient boosting achieved the highest scores, with test F1-scores of approximately 0.775 and ROC--AUC values of approximately 0.84. Linear models, namely logistic regression and the calibrated linear SVM, performed slightly worse, with test F1-scores around 0.75. In contrast, Gaussian Naive Bayes lagged behind with a substantially lower F1-score of approximately 0.66, despite exhibiting extremely high precision for the chimeric class.

\input{tables/baseline_models_noq}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{figures/baseline_models_pair.png}
  \caption{Test F1 of all baseline classifiers.}
  \label{fig:baseline_f1}
\end{figure}

\section{Effect of Hyperparameter Tuning}

To assess whether performance could be improved further, ten model families underwent randomised hyperparameter search. The tuned metrics are summarised in Table~\ref{tab:tuned_models_noq}. Overall, tuning yielded modest but consistent gains for tree-based ensembles and boosting methods, while leaving linear models essentially unchanged or slightly worse.

CatBoost, gradient boosting, LightGBM, random forest, bagging trees, and extra trees experienced small increases in test F1 after tuning, typically on the order of $\Delta \mathrm{F1} \approx 0.002$--0.006, with corresponding improvements in ROC--AUC of up to approximately $\Delta \mathrm{AUC} \approx 0.009$. In contrast, XGBoost and the multilayer perceptron showed negligible change or slight decreases in F1, while linear models did not benefit from tuning.

After tuning, gradient boosting achieved the best overall test performance, with a test F1-score of 0.776 and a ROC--AUC of 0.846. LightGBM and bagging trees followed closely, attaining test F1-scores of 0.774 and 0.772 and ROC--AUC values of 0.843 and 0.842, respectively. Random forest also improved modestly to a test F1-score of 0.772 with a ROC--AUC of 0.839. CatBoost, with a test F1-score of 0.775 and ROC--AUC of 0.843, achieved marginal changes relative to its baseline performance.


\input{tables/tuned_models_noq}

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figures/f1_auc_tuning_pair.png}
  \caption{Comparison of test F1 (left) and ROC--AUC (right) for baseline and tuned models.}
  \label{fig:f1_auc_tuning}
\end{figure}

Because improvements are small and within cross-validation variability, tuning was interpreted as stabilising and slightly refining the models rather than completely altering their behaviour or their relative ranking.

\section{Detailed Evaluation of Representative Models}

For interpretability and diversity, four tuned models were selected for deeper analysis: CatBoost (best-performing boosted tree), scikit-learn gradient boosting (canonical gradient-boosting implementation), random forest (non-boosted ensemble baseline), and $L_2$-regularised logistic regression (linear baseline). All models were trained on the engineered feature set and evaluated on the same held-out test data.

\subsection{Confusion Matrices and Error Patterns}

Classification reports and confusion matrices for the four models reveal consistent patterns. CatBoost and gradient boosting both achieved overall accuracy around 0.81, with similar macro-averaged F1 scores (0.80--0.805). For CatBoost, precision and recall for clean reads were 0.74 and 0.95, respectively, while for chimeric reads they were 0.94 and 0.66 (F1 = 0.775). Gradient boosting showed nearly identical trade-offs, with clean read precision/recall of 0.74/0.96 and chimeric read precision/recall of 0.94/0.66 (F1 = 0.777).

Bagging trees achieved slightly lower accuracy (0.805) and chimeric F1 (0.772), whereas the multilayer perceptron (MLP) attained the lowest accuracy (0.793) and chimeric F1 (0.749), despite achieving high chimeric precision (0.95) at the cost of lower recall (0.62).

Across all models, errors were asymmetric: false negatives (chimeric reads predicted as clean) were more frequent than false positives. For instance, CatBoost misclassified 1{,}352 chimeric reads as clean but only 215 clean reads as chimeric, while gradient boosting misclassified 1{,}352 chimeric reads as clean and 181 clean reads as chimeric. This pattern indicates that both models are conservative, prioritizing the avoidance of false chimera calls even if some true chimeras are missed. Consultation with PGC Visayas suggested that this conservative behavior is generally acceptable, although further evaluation is needed to assess its impact on downstream analyses.


\begin{figure}[H]
  \centering
  \includegraphics[width=0.45\linewidth]{figures/cm_catboost_pair.png}
  \includegraphics[width=0.45\linewidth]{figures/cm_gradient_boosting_pair.png}\\[4pt]
  \includegraphics[width=0.45\linewidth]{figures/cm_bagging_trees_pair.png}
  \includegraphics[width=0.45\linewidth]{figures/cm_mlp_pair.png}
  \caption{Confusion matrices for the four representative models on the held-out test set.}
  \label{fig:confusion_matrices}
\end{figure}

\subsection{ROC and Precision--Recall Curves}

Receiver operating characteristic (ROC) and precision--recall (PR) curves as shown in Figure~\ref{fig:roc_pr_curves} further support the similarity among the top models. The three tree-based ensembles (CatBoost, gradient boosting, bagging trees) achieved ROC--AUC values of approximately 0.84 and average precision (AP) around 0.88. MLP performed slightly worse (AUC $\approx 0.82$, AP $\approx 0.87$) but still substantially better than the dummy baseline.

The PR curves show that precision remains above 0.9 across a broad range of recall values (up to roughly 0.5--0.6), after which precision gradually declines. This behaviour indicates that the models can assign very high confidence to a subset of chimeric reads, while more ambiguous reads can only be recovered by accepting lower precision.

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figures/roc_pr_curves_pair.png}
  \caption{ROC (left) and precision--recall (right) curves for the four representative models on the held-out test set.}
  \label{fig:roc_pr_curves}
\end{figure}

\section{Feature Importance}

\subsection{Permutation Importance of Individual Features}

To understand how each classifier made predictions, feature importance was quantified using permutation importance. This analysis was applied to four representative models: CatBoost, Gradient Boosting, Bagging Trees, and an MLP.

As shown in Figure~\ref{fig:all_models_imp}, \texttt{total\_clipped\_bases} consistently provides a strong predictive signal across all models, particularly in Gradient Boosting (importance = 0.117) and Bagging Trees (importance = 0.274). CatBoost assigns high importance to both \texttt{total\_clipped\_bases} (0.062) and \texttt{kmer\_js\_divergence} (0.045), while MLP relies on \texttt{total\_clipped\_bases} and soft-clipping features (\texttt{softclip\_left}, \texttt{softclip\_right}) as primary signals. Gradient Boosting emphasizes \texttt{kmer\_js\_divergence} and \texttt{kmer\_cosine\_diff} alongside \texttt{total\_clipped\_bases}, but soft-clipping features contribute less.

Microhomology features (\texttt{microhomology\_length} and \texttt{microhomology\_gc}) provide minimal predictive value in all models, and some alignment-based split-read metrics (e.g., \texttt{sa\_min\_delta\_pos}, \texttt{sa\_max\_delta\_pos}) are leveraged primarily by the MLP. Overall, these results indicate that accurate detection of chimeric reads relies on both alignment-based signals and k-mer compositional information, with explicit microhomology features contributing little. Combining multiple feature types enhances model sensitivity and specificity.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/catboost_imp_pair.png}
        \caption{CatBoost}
        \label{fig:catboost_imp}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/gradient_imp_pair.png}
        \caption{Gradient Boosting}
        \label{fig:gradient_imp}
    \end{subfigure}

    \vspace{0.5em}

    \begin{subfigure}[b]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/bagging_trees_imp_pair.png}
        \caption{Bagging Trees}
        \label{fig:bagging_trees_imp}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/mlp_imp_pair.png}
        \caption{Multi-Layer Perceptron (MLP)}
        \label{fig:mlp_imp}
    \end{subfigure}

    \caption{Permutation-based feature importance for four representative classifiers.}
    \label{fig:all_models_imp}
\end{figure}

\subsection{Feature Family Importance}

To evaluate broader predictive signals, features were grouped into five families: 
SA\_structure (supplementary alignment and segment metrics, e.g., 
\texttt{has\_sa}, \texttt{sa\_count}, \texttt{sa\_min\_delta\_pos}, \texttt{sa\_mean\_nm}), 
Clipping (\texttt{softclip\_left}, \texttt{softclip\_right}, \texttt{total\_clipped\_bases}, 
\texttt{breakpoint\_read\_pos}), 
Kmer\_jump (\texttt{kmer\_cosine\_diff}, \texttt{kmer\_js\_divergence}), 
Micro\_homology (\texttt{microhomology\_length}, \texttt{microhomology\_gc}), 
and Other (e.g., \texttt{mapq}).

Aggregated analyses reveal consistent patterns across models. In CatBoost, the Clipping family dominates with cumulative importance 0.127, followed by Kmer\_jump (0.074), while Other (0.0045), SA\_structure (0.0033), and Micro\_homology (0.0013) contribute minimally. Gradient Boosting shows a similar trend, with Clipping (0.134) and Kmer\_jump (0.096) providing most predictive power, and the remaining families contributing negligibly. Bagging Trees emphasizes Clipping even more strongly (0.277), with Kmer\_jump secondary (0.037), and SA\_structure, Micro\_homology, and Other remaining minor contributors. Interestingly, the MLP exhibits a different pattern, prioritizing Clipping (0.104) and SA\_structure (0.078), while Kmer\_jump (0.000034) and Micro\_homology (0.000091) have almost no effect.

Both feature-level and aggregated analyses indicate that accurate detection of chimeric reads in this dataset relies primarily on alignment irregularities captured by Clipping features and, in most tree-based models, on k-mer compositional shifts (Kmer\_jump), which often arise from PCR-induced template switching events. Explicit microhomology features contribute minimally, and some reliance on SA\_structure signals is observed only in the MLP.


\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{catboost_family_pair.png}
        \caption{CatBoost}
        \label{fig:catboost_family}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{gradient_family_pair.png}
        \caption{Gradient Boosting}
        \label{fig:gb_family}
    \end{subfigure}
    
    \vspace{0.5em}
    
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{randomforest_family.png} %change to bagging tree
        \caption{Random Forest}
        \label{fig:rf_family}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{logreg_family.png} %change to mlp
        \caption{L$_2$-regularized Logistic Regression}
        \label{fig:logreg_family}
    \end{subfigure}

    \caption{Aggregated feature family importance across four models.}
    \label{fig:feature_family_all}
\end{figure}

\section{Feature Selection}

Feature selection was performed to identify the smallest subset reaching 95\% cumulative importance. Three models were evaluated as references: the full model with all 23 features, a reduced model with the top-\(k\) features, and an ablation model excluding microhomology features, using a tuned CatBoost classifier to assess feature contributions and overall classification performance.

\subsection{Cumulative Importance Curve}

The cumulative importance curve was computed using the tuned Gradient Boosting classifier. Figure~\ref{fig:cumulative_importance} illustrates the contribution of features sorted by importance. The curve rises steeply for the top features and then gradually plateaus, indicating that a small number of features capture most of the model's predictive power. A cumulative importance of 95\% is reached at \(k = 4\) features, which are \texttt{total\_clipped\_bases}, \texttt{kmer\_js\_divergence}, \texttt{kmer\_cosine\_diff}, and \texttt{softclip\_left}.


\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{figures/cumulative_gradient_pair.png}
\caption{Cumulative importance curve of features sorted by importance.}
\label{fig:cumulative_importance}
\end{figure}

\subsection{Performance Comparison Across Feature Sets}

Classification performance was compared across three feature sets using a tuned Gradient Boosting classifier. The full model, incorporating all 24 engineered features, achieved an F1 score of 0.7765 and a ROC--AUC of 0.8459. A reduced model using only the top four features (\texttt{total\_clipped\_bases}, \texttt{kmer\_js\_divergence}, \texttt{kmer\_cosine\_diff}, and \texttt{softclip\_left}) achieved nearly equivalent performance with an F1 of 0.7768 and a ROC--AUC of 0.8369. An ablation model excluding microhomology features (\texttt{microhomology\_length} and \texttt{microhomology\_gc}) also performed comparably, with an F1 of 0.7761 and ROC--AUC of 0.8444. These results indicate that clipping and k-mer features capture almost all predictive signal, while microhomology features are largely redundant in this dataset.

\begin{table}[H]
\centering
\caption{Test set performance of three feature set variants using tuned Gradient Boosting.}
\label{tab:gb_feature_sets}
\begin{tabular}{lrrr}
\toprule
Variant & No. of Features & Test F1 & ROC--AUC \\
\midrule
Full Gradient Boost & 24 & 0.7765 & 0.8459 \\
Selected (top-4) & 4 & 0.7768 & 0.8369 \\
No microhomology & 22 & 0.7761 & 0.8444 \\
\bottomrule
\end{tabular}
\end{table}


Figure~\ref{fig:gradient_boost_three_sets} presents a bar chart comparing F1 and ROC--AUC across the three variants, with the x-axis showing the model variants and two bars per group representing the F1 and ROC--AUC values.

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{figures/gradient_feature_sets_pair.png}
\caption{Comparison of F1 and ROC--AUC for the full, top-4 selected, and no-microhomology feature set variants.}
\label{fig:gradient_boost_three_sets}
\end{figure}

\subsection{Interpretation and Final Feature Set Choice}

The full 23-feature model is retained as the primary configuration for the remainder of the study, while the four-feature subset serves as a lightweight alternative. Clipping features reflect alignment junctions and mapping disruptions typical of chimeric reads, and k-mer divergence captures changes in sequence composition across breakpoints. Microhomology features appear largely redundant, as their signal is either indirectly represented by clipping and k-mer features or not strongly expressed in the simulation dataset.


\section{Convolutional Neural Network (CNN) Performance and Classification Results}

As shown in Figure~\ref{fig:cnn_training}, the CNN demonstrates stable convergence and strong generalization performance on the balanced test set ($n = 8000$; 4000 clean and 4000 chimeric). Training loss decreases consistently from 0.693 at epoch 1 to 0.110 at epoch 15, while test accuracy improves from 0.500 to 0.893, indicating effective feature extraction and progressive learning of sequence patterns. Test loss declines in parallel with training loss and reaches its minimum of 0.307 at epoch 12, followed by a temporary increase at epochs 13--14 despite continued reductions in training loss, suggesting mild overfitting. However, performance stabilizes by epoch 15, which yields the highest test accuracy of 0.893 with a test loss of 0.310, indicating that generalization remains strong overall. In addition, the model achieves a ROC--AUC of 0.9508, demonstrating strong discrimination between clean and chimeric reads across decision thresholds.

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{figures/cnn_training.png}
  \caption{Training and Test Performance of the CNN Model Across 15 Epochs}
  \label{fig:cnn_training}
\end{figure}

Class-wise performance indicates that the model is strongly biased toward correctly identifying chimeric reads. Specifically, it achieved a recall of 0.9495 for the chimeric class, correctly detecting 3798 out of 4000 chimeric sequences, while recall for the clean class was lower at 0.8370, with 3348 out of 4000 clean reads correctly classified. The confusion matrix (Figure~\ref{fig:cnn_confusion}) reveals that only 202 chimeric reads were misclassified as clean, whereas a larger number of clean reads (652) were incorrectly labeled as chimeric. This asymmetry results in a chimeric precision of 0.8535 and an F1-score of 0.8989. These findings indicate that the model prioritizes minimizing false negatives for chimeric reads, thereby maximizing detection sensitivity, at the cost of a higher false-positive rate among clean reads. However, the high F1-score shows that the model maintains a strong balance between sensitivity and predictive reliability for the chimeric class, suggesting that the high detection rate is not achieved at the expense of excessive false-positive predictions.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.6\textwidth]{figures/cnn_confusion.png}
  \caption{Confusion Matrix of CNN Classification Performance on Clean and Chimeric Reads}
  \label{fig:cnn_confusion}
\end{figure}

\section{Summary of Findings}

///NOTE: TO BE REVISED AFTER FINAL CHECKS ON THE FULL RESULTS

All evaluated machine learning models substantially outperformed the dummy baseline, demonstrating that the engineered feature set contains meaningful signals for detecting PCR-induced chimeric reads. Across classifiers, the best-performing models achieved test F1-scores of approximately 0.77 and ROC--AUC values around 0.84 on held-out simulated mitochondrial reads, indicating reliable discrimination between clean and chimeric sequences. Among the tested approaches, tree-based ensemble and boosting methods consistently showed the strongest and most stable performance. In particular, CatBoost and Gradient Boosting ranked among the top models across multiple evaluation metrics, both before and after hyperparameter tuning. These results suggest that non-linear ensemble methods are well suited to capturing the interaction between alignment-derived and sequence-derived features in this setting.

Analysis of feature behaviour revealed clear differences in how effectively feature groups distinguished clean and chimeric reads. Alignment- and clipping-based features, such as soft-clipping measures and total clipped bases, showed strong separation between clean and chimeric reads and emerged as the most informative signals. K-mer divergence features provided additional but weaker separation, contributing complementary information beyond alignment irregularities. In contrast, microhomology features and several supplementary alignment (SA) structure metrics exhibited minimal class separation and contributed little to overall predictive performance.

Feature selection results further supported these observations. A reduced subset of four features, dominated by clipping-based and k-mer divergence metrics, achieved nearly identical performance to the full 23-feature model. Moreover, removing explicit microhomology features did not degrade performance and in some cases resulted in slightly improved metrics, suggesting that these features are largely redundant under the simulated conditions tested.

Overall, these findings suggest that alignment-based and k-mer--based features provide sufficient signal to detect PCR-induced chimeric reads in simulated mitochondrial data, supporting the use of a compact and interpretable machine learning approach as a pre-assembly chimera detection step.
